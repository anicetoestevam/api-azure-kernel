{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Passo 1: Instale as bibliotecas necessárias\n",
        "!pip install openai python-dotenv semantic-kernel --quiet\n",
        "\n",
        "# Passo 2: Importe as bibliotecas\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "import semantic_kernel as sk\n",
        "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
        "from semantic_kernel.core_plugins.text_plugin import TextPlugin\n",
        "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
        "\n",
        "# Passo 3: Defina suas variáveis de ambiente\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://eitasenhor.openai.azure.com/\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"---\"\n",
        "os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"] = \"gpt-35-turbo\"  # Nome do modelo implantado no Azure\n",
        "\n",
        "# Passo 4: Crie o cliente da API do Azure OpenAI\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
        "    api_version=\"2024-02-01\"\n",
        ")\n",
        "\n",
        "print(\"Fazendo chamada direta à API do Azure OpenAI...\\n\")\n",
        "\n",
        "try:\n",
        "    response = client.chat.completions.create(\n",
        "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"Explique o conceito de sistemas distribuídos.\"}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=200\n",
        "    )\n",
        "\n",
        "    print(\"✅ Resposta da API do Azure OpenAI:\")\n",
        "    print(response.choices[0].message.content)\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erro ao chamar a API: {e}\")\n",
        "\n",
        "# Passo 5: Inicialize o Semantic Kernel\n",
        "print(\"\\nIniciando o Semantic Kernel...\\n\")\n",
        "\n",
        "try:\n",
        "    kernel = sk.Kernel()\n",
        "\n",
        "    # Adiciona o serviço de chat usando o Azure OpenAI\n",
        "    kernel.add_service(\n",
        "        service=AzureChatCompletion(\n",
        "            deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
        "            endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
        "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Plugin de texto básico (exemplo)\n",
        "    text_plugin = TextPlugin()\n",
        "    kernel.add_plugin(plugin=text_plugin, plugin_name=\"text\")\n",
        "\n",
        "    # Função semântica simples (cria uma função inline)\n",
        "    prompt = \"\"\"\n",
        "    Responda à seguinte pergunta:\n",
        "    {{ $input }}\n",
        "    \"\"\"\n",
        "\n",
        "    summarize_function = kernel.add_function(\n",
        "        function_name=\"summarize\",\n",
        "        plugin_name=\"text\",\n",
        "        prompt=prompt,\n",
        "        description=\"Responde a perguntas fornecidas pelo usuário.\",\n",
        "        input_description=\"Pergunta do usuário.\"\n",
        "    )\n",
        "\n",
        "    # Execute a função com um input real\n",
        "    result = await kernel.invoke(summarize_function, input=\"O que é topologia de rede em estrela?\")\n",
        "\n",
        "    print(\"✅ Resultado do Semantic Kernel:\")\n",
        "    print(result)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Erro ao usar Semantic Kernel: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwqwNwkOuUd8",
        "outputId": "c9e19c29-a241-4d87-a797-b4b87eeb3777"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fazendo chamada direta à API do Azure OpenAI...\n",
            "\n",
            "✅ Resposta da API do Azure OpenAI:\n",
            "Sistemas distribuídos referem-se a um conjunto de computadores interconectados que trabalham juntos para alcançar um objetivo comum. Esses computadores estão localizados em diferentes locais físicos e se comunicam através de uma rede de computadores. Em um sistema distribuído, cada computador tem sua própria memória e processador, e pode operar de forma independente, mas ao mesmo tempo colaborar com os outros computadores para realizar tarefas complexas.\n",
            "\n",
            "Esses sistemas são projetados para melhorar o desempenho, escalabilidade e disponibilidade de serviços e aplicações, distribuindo a carga de trabalho entre os computadores da rede. Eles também oferecem maior tolerância a falhas, uma vez que, se um dos computadores falhar, os outros podem continuar operando sem interrupções.\n",
            "\n",
            "Os sistemas distribuídos são amplamente utilizados em diferentes áreas, como redes sociais\n",
            "\n",
            "Iniciando o Semantic Kernel...\n",
            "\n",
            "✅ Resultado do Semantic Kernel:\n",
            "A topologia de rede em estrela é um tipo de configuração de rede em que todos os dispositivos estão conectados a um ponto central, chamado de hub. Neste tipo de topologia, cada dispositivo na rede se comunica diretamente apenas com o hub, que é responsável por transmitir as informações para os demais dispositivos. Isso resulta em uma rede mais organizada, fácil de gerenciar e de identificar problemas de conexão. No entanto, se o hub falhar, toda a rede pode ser afetada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ED97zIKTtZvc"
      },
      "outputs": [],
      "source": []
    }
  ]
}